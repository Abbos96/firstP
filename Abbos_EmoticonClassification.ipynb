{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abbos_EmoticonClassification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hziowOLD4PI1",
        "outputId": "85ea5d53-4208-46fb-f707-2fb6e7b5ef43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQWXlodzgvF0"
      },
      "source": [
        "train_data_dir = '/gdrive/My Drive/dataset/train'\n",
        "validation_data_dir = '/gdrive/My Drive/dataset/val'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKOYzTx-hHby"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense \n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5msXfhOhfrz",
        "outputId": "91d8d61b-4465-4072-e838-72327d00d39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        " train_data_dir,\n",
        " target_size=(200, 200),\n",
        " batch_size=32,\n",
        " class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        " validation_data_dir,\n",
        " target_size=(200, 200),\n",
        " batch_size=32,\n",
        " class_mode='categorical')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13125 images belonging to 8 classes.\n",
            "Found 558 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrPg1a4birtz",
        "outputId": "41b706f0-cde2-4195-f4c4-3fcd3ce111d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(200,200,3)),\n",
        "    Conv2D(16, kernel_size=(3,3), activation='relu', strides=(1, 1)),\n",
        "    Conv2D(16, kernel_size=(3,3), activation='relu', strides=(1, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(32, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Conv2D(32, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3,3), activation='relu',strides=(1, 1), padding='valid'),\n",
        "    Conv2D(64, kernel_size=(3,3), activation='relu',strides=(1, 1), padding='valid'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "    Conv2D(128, kernel_size=(3,3), activation='relu', padding='valid', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    Conv2D(128, kernel_size=(2,2), activation='relu', strides=(1, 1), padding='valid'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(optimizer=opt, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 196, 196, 16)      2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 196, 196, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 98, 98, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 94, 94, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 94, 94, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 43, 43, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 43, 43, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 19, 19, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 128)       65664     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                2654272   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 264       \n",
            "=================================================================\n",
            "Total params: 2,869,176\n",
            "Trainable params: 2,868,696\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSi1ygmtmkss"
      },
      "source": [
        "total_train = 13125\n",
        "total_val = 558\n",
        "epochs = 10\n",
        "batch_size = 500\n",
        "esc = EarlyStopping(monitor='val_acc', patience=2)\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"/gdrive/My Drive/best_model.h5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7nShT0Kmrxj",
        "outputId": "388b191d-ea1e-4a74-c1d3-7900a75047da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_val // batch_size,\n",
        "    callbacks=[checkpoint, esc]\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-e143733db700>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.52502, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 3.5250 - accuracy: 0.1562\n",
            "Epoch 00001: loss improved from 3.52502 to 3.21484, saving model to /gdrive/My Drive/best_model.h5\n",
            " 2/26 [=>............................] - ETA: 1:53 - loss: 3.2148 - accuracy: 0.3438\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 3/26 [==>...........................] - ETA: 2:28 - loss: 3.3166 - accuracy: 0.3958\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 4/26 [===>..........................] - ETA: 2:41 - loss: 3.3931 - accuracy: 0.4141\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 5/26 [====>.........................] - ETA: 2:37 - loss: 3.4809 - accuracy: 0.4250\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 6/26 [=====>........................] - ETA: 2:34 - loss: 3.3671 - accuracy: 0.4167\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 7/26 [=======>......................] - ETA: 2:29 - loss: 3.3877 - accuracy: 0.4152\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 8/26 [========>.....................] - ETA: 2:23 - loss: 3.4919 - accuracy: 0.4141\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            " 9/26 [=========>....................] - ETA: 2:17 - loss: 3.4425 - accuracy: 0.4132\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "10/26 [==========>...................] - ETA: 2:10 - loss: 3.4235 - accuracy: 0.4156\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "11/26 [===========>..................] - ETA: 2:03 - loss: 3.4888 - accuracy: 0.4176\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "12/26 [============>.................] - ETA: 1:56 - loss: 3.4276 - accuracy: 0.4245\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "13/26 [==============>...............] - ETA: 1:49 - loss: 3.3936 - accuracy: 0.4279\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "14/26 [===============>..............] - ETA: 1:41 - loss: 3.3783 - accuracy: 0.4241\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "15/26 [================>.............] - ETA: 1:33 - loss: 3.3422 - accuracy: 0.4292\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "16/26 [=================>............] - ETA: 1:25 - loss: 3.3323 - accuracy: 0.4375\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "17/26 [==================>...........] - ETA: 1:17 - loss: 3.2996 - accuracy: 0.4393\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "18/26 [===================>..........] - ETA: 1:08 - loss: 3.3162 - accuracy: 0.4392\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "19/26 [====================>.........] - ETA: 1:00 - loss: 3.3074 - accuracy: 0.4391\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "20/26 [======================>.......] - ETA: 51s - loss: 3.2885 - accuracy: 0.4422 \n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "21/26 [=======================>......] - ETA: 43s - loss: 3.2559 - accuracy: 0.4449\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "22/26 [========================>.....] - ETA: 34s - loss: 3.2633 - accuracy: 0.4517\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "23/26 [=========================>....] - ETA: 25s - loss: 3.2375 - accuracy: 0.4511\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "24/26 [==========================>...] - ETA: 17s - loss: 3.2384 - accuracy: 0.4492\n",
            "Epoch 00001: loss did not improve from 3.21484\n",
            "25/26 [===========================>..] - ETA: 8s - loss: 3.2177 - accuracy: 0.4550 \n",
            "Epoch 00001: loss improved from 3.21484 to 3.20243, saving model to /gdrive/My Drive/best_model.h5\n",
            "26/26 [==============================] - ETA: 0s - loss: 3.2024 - accuracy: 0.4591WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 243s 9s/step - loss: 3.2024 - accuracy: 0.4591 - val_loss: 148.6161 - val_accuracy: 0.4062\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: loss improved from 3.20243 to 2.76170, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 2.7617 - accuracy: 0.4375\n",
            "Epoch 00002: loss improved from 2.76170 to 2.67994, saving model to /gdrive/My Drive/best_model.h5\n",
            " 2/26 [=>............................] - ETA: 2:24 - loss: 2.6799 - accuracy: 0.4844\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 3/26 [==>...........................] - ETA: 2:26 - loss: 2.7274 - accuracy: 0.4792\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 4/26 [===>..........................] - ETA: 2:23 - loss: 2.7373 - accuracy: 0.4922\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 5/26 [====>.........................] - ETA: 2:27 - loss: 2.7803 - accuracy: 0.5000\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 6/26 [=====>........................] - ETA: 2:28 - loss: 2.7942 - accuracy: 0.4844\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 7/26 [=======>......................] - ETA: 2:25 - loss: 2.7757 - accuracy: 0.4688\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 8/26 [========>.....................] - ETA: 2:18 - loss: 2.7330 - accuracy: 0.4805\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            " 9/26 [=========>....................] - ETA: 2:13 - loss: 2.6962 - accuracy: 0.4965\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            "10/26 [==========>...................] - ETA: 2:05 - loss: 2.7096 - accuracy: 0.4875\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            "11/26 [===========>..................] - ETA: 1:59 - loss: 2.6830 - accuracy: 0.4830\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            "12/26 [============>.................] - ETA: 1:51 - loss: 2.6873 - accuracy: 0.4896\n",
            "Epoch 00002: loss did not improve from 2.67994\n",
            "13/26 [==============>...............] - ETA: 1:43 - loss: 2.6925 - accuracy: 0.4928\n",
            "Epoch 00002: loss improved from 2.67994 to 2.66626, saving model to /gdrive/My Drive/best_model.h5\n",
            "14/26 [===============>..............] - ETA: 1:35 - loss: 2.6663 - accuracy: 0.5000\n",
            "Epoch 00002: loss improved from 2.66626 to 2.65576, saving model to /gdrive/My Drive/best_model.h5\n",
            "15/26 [================>.............] - ETA: 1:26 - loss: 2.6558 - accuracy: 0.4979\n",
            "Epoch 00002: loss improved from 2.65576 to 2.63480, saving model to /gdrive/My Drive/best_model.h5\n",
            "16/26 [=================>............] - ETA: 1:19 - loss: 2.6348 - accuracy: 0.4961\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "17/26 [==================>...........] - ETA: 1:11 - loss: 2.6564 - accuracy: 0.4963\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "18/26 [===================>..........] - ETA: 1:03 - loss: 2.6647 - accuracy: 0.4913\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "19/26 [====================>.........] - ETA: 55s - loss: 2.6518 - accuracy: 0.4951 \n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "20/26 [======================>.......] - ETA: 47s - loss: 2.6478 - accuracy: 0.4922\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "21/26 [=======================>......] - ETA: 40s - loss: 2.6402 - accuracy: 0.4926\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "22/26 [========================>.....] - ETA: 32s - loss: 2.6361 - accuracy: 0.4957\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "23/26 [=========================>....] - ETA: 24s - loss: 2.6414 - accuracy: 0.4918\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "24/26 [==========================>...] - ETA: 16s - loss: 2.6438 - accuracy: 0.4883\n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "25/26 [===========================>..] - ETA: 8s - loss: 2.6481 - accuracy: 0.4875 \n",
            "Epoch 00002: loss did not improve from 2.63480\n",
            "26/26 [==============================] - ETA: 0s - loss: 2.6358 - accuracy: 0.4916WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 224s 9s/step - loss: 2.6358 - accuracy: 0.4916 - val_loss: 28.3070 - val_accuracy: 0.3438\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: loss improved from 2.63480 to 2.35837, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 2.3584 - accuracy: 0.5625\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 2/26 [=>............................] - ETA: 1:27 - loss: 2.7193 - accuracy: 0.4688\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 3/26 [==>...........................] - ETA: 1:52 - loss: 2.6339 - accuracy: 0.5000\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 4/26 [===>..........................] - ETA: 2:04 - loss: 2.5472 - accuracy: 0.5156\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 5/26 [====>.........................] - ETA: 2:08 - loss: 2.5420 - accuracy: 0.5188\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 6/26 [=====>........................] - ETA: 2:05 - loss: 2.5489 - accuracy: 0.5208\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 7/26 [=======>......................] - ETA: 2:02 - loss: 2.5399 - accuracy: 0.5179\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 8/26 [========>.....................] - ETA: 1:57 - loss: 2.5435 - accuracy: 0.5234\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            " 9/26 [=========>....................] - ETA: 1:53 - loss: 2.5152 - accuracy: 0.5312\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "10/26 [==========>...................] - ETA: 1:49 - loss: 2.5121 - accuracy: 0.5219\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "11/26 [===========>..................] - ETA: 1:44 - loss: 2.4880 - accuracy: 0.5256\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "12/26 [============>.................] - ETA: 1:39 - loss: 2.4547 - accuracy: 0.5391\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "13/26 [==============>...............] - ETA: 1:33 - loss: 2.4365 - accuracy: 0.5457\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "14/26 [===============>..............] - ETA: 1:25 - loss: 2.4365 - accuracy: 0.5424\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "15/26 [================>.............] - ETA: 1:19 - loss: 2.4362 - accuracy: 0.5354\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "16/26 [=================>............] - ETA: 1:12 - loss: 2.4363 - accuracy: 0.5332\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "17/26 [==================>...........] - ETA: 1:05 - loss: 2.4259 - accuracy: 0.5331\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "18/26 [===================>..........] - ETA: 57s - loss: 2.4329 - accuracy: 0.5347 \n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "19/26 [====================>.........] - ETA: 50s - loss: 2.4207 - accuracy: 0.5345\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "20/26 [======================>.......] - ETA: 43s - loss: 2.4103 - accuracy: 0.5281\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "21/26 [=======================>......] - ETA: 36s - loss: 2.4111 - accuracy: 0.5283\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "22/26 [========================>.....] - ETA: 29s - loss: 2.3984 - accuracy: 0.5312\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "23/26 [=========================>....] - ETA: 21s - loss: 2.3938 - accuracy: 0.5312\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "24/26 [==========================>...] - ETA: 14s - loss: 2.4028 - accuracy: 0.5339\n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "25/26 [===========================>..] - ETA: 7s - loss: 2.4001 - accuracy: 0.5362 \n",
            "Epoch 00003: loss did not improve from 2.35837\n",
            "26/26 [==============================] - ETA: 0s - loss: 2.3899 - accuracy: 0.5397WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 206s 8s/step - loss: 2.3899 - accuracy: 0.5397 - val_loss: 7.6948 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: loss improved from 2.35837 to 2.28564, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 2.2856 - accuracy: 0.5938\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 2/26 [=>............................] - ETA: 1:30 - loss: 2.5718 - accuracy: 0.5312\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 3/26 [==>...........................] - ETA: 1:52 - loss: 2.7076 - accuracy: 0.5104\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 4/26 [===>..........................] - ETA: 2:00 - loss: 2.6930 - accuracy: 0.5156\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 5/26 [====>.........................] - ETA: 1:59 - loss: 2.5954 - accuracy: 0.5000\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 6/26 [=====>........................] - ETA: 1:56 - loss: 2.5405 - accuracy: 0.4948\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 7/26 [=======>......................] - ETA: 1:56 - loss: 2.5124 - accuracy: 0.4911\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 8/26 [========>.....................] - ETA: 1:56 - loss: 2.4875 - accuracy: 0.4961\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            " 9/26 [=========>....................] - ETA: 1:51 - loss: 2.4514 - accuracy: 0.5069\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "10/26 [==========>...................] - ETA: 1:45 - loss: 2.4097 - accuracy: 0.5156\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "11/26 [===========>..................] - ETA: 1:39 - loss: 2.4446 - accuracy: 0.5085\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "12/26 [============>.................] - ETA: 1:33 - loss: 2.4604 - accuracy: 0.5026\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "13/26 [==============>...............] - ETA: 1:28 - loss: 2.4632 - accuracy: 0.4928\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "14/26 [===============>..............] - ETA: 1:21 - loss: 2.4502 - accuracy: 0.5022\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "15/26 [================>.............] - ETA: 1:14 - loss: 2.4470 - accuracy: 0.5063\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "16/26 [=================>............] - ETA: 1:08 - loss: 2.4404 - accuracy: 0.5137\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "17/26 [==================>...........] - ETA: 1:01 - loss: 2.4429 - accuracy: 0.5074\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "18/26 [===================>..........] - ETA: 55s - loss: 2.4441 - accuracy: 0.5017 \n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "19/26 [====================>.........] - ETA: 48s - loss: 2.4209 - accuracy: 0.5033\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "20/26 [======================>.......] - ETA: 41s - loss: 2.4121 - accuracy: 0.5078\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "21/26 [=======================>......] - ETA: 34s - loss: 2.3906 - accuracy: 0.5134\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "22/26 [========================>.....] - ETA: 27s - loss: 2.3916 - accuracy: 0.5185\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "23/26 [=========================>....] - ETA: 20s - loss: 2.3761 - accuracy: 0.5231\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "24/26 [==========================>...] - ETA: 13s - loss: 2.3764 - accuracy: 0.5247\n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "25/26 [===========================>..] - ETA: 6s - loss: 2.3812 - accuracy: 0.5263 \n",
            "Epoch 00004: loss did not improve from 2.28564\n",
            "26/26 [==============================] - ETA: 0s - loss: 2.3674 - accuracy: 0.5264WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 189s 7s/step - loss: 2.3674 - accuracy: 0.5264 - val_loss: 4.0208 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: loss improved from 2.28564 to 2.13865, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 2.1387 - accuracy: 0.5938\n",
            "Epoch 00005: loss did not improve from 2.13865\n",
            " 2/26 [=>............................] - ETA: 1:08 - loss: 2.1507 - accuracy: 0.5625\n",
            "Epoch 00005: loss improved from 2.13865 to 2.13404, saving model to /gdrive/My Drive/best_model.h5\n",
            " 3/26 [==>...........................] - ETA: 1:41 - loss: 2.1340 - accuracy: 0.5729\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 4/26 [===>..........................] - ETA: 1:50 - loss: 2.2026 - accuracy: 0.5312\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 5/26 [====>.........................] - ETA: 1:53 - loss: 2.2240 - accuracy: 0.5312\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 6/26 [=====>........................] - ETA: 1:53 - loss: 2.2492 - accuracy: 0.5260\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 7/26 [=======>......................] - ETA: 1:51 - loss: 2.2516 - accuracy: 0.5223\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 8/26 [========>.....................] - ETA: 1:48 - loss: 2.2296 - accuracy: 0.5312\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            " 9/26 [=========>....................] - ETA: 1:44 - loss: 2.2081 - accuracy: 0.5556\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "10/26 [==========>...................] - ETA: 1:40 - loss: 2.1858 - accuracy: 0.5625\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "11/26 [===========>..................] - ETA: 1:34 - loss: 2.1512 - accuracy: 0.5795\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "12/26 [============>.................] - ETA: 1:31 - loss: 2.1761 - accuracy: 0.5729\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "13/26 [==============>...............] - ETA: 1:24 - loss: 2.1846 - accuracy: 0.5625\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "14/26 [===============>..............] - ETA: 1:18 - loss: 2.1778 - accuracy: 0.5603\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "15/26 [================>.............] - ETA: 1:12 - loss: 2.1603 - accuracy: 0.5729\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "16/26 [=================>............] - ETA: 1:05 - loss: 2.1460 - accuracy: 0.5762\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "17/26 [==================>...........] - ETA: 58s - loss: 2.1495 - accuracy: 0.5735 \n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "18/26 [===================>..........] - ETA: 52s - loss: 2.1473 - accuracy: 0.5781\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "19/26 [====================>.........] - ETA: 45s - loss: 2.1362 - accuracy: 0.5855\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "20/26 [======================>.......] - ETA: 38s - loss: 2.1428 - accuracy: 0.5781\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "21/26 [=======================>......] - ETA: 32s - loss: 2.1567 - accuracy: 0.5729\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "22/26 [========================>.....] - ETA: 25s - loss: 2.1554 - accuracy: 0.5724\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "23/26 [=========================>....] - ETA: 19s - loss: 2.1480 - accuracy: 0.5734\n",
            "Epoch 00005: loss did not improve from 2.13404\n",
            "24/26 [==========================>...] - ETA: 12s - loss: 2.1411 - accuracy: 0.5755\n",
            "Epoch 00005: loss improved from 2.13404 to 2.12727, saving model to /gdrive/My Drive/best_model.h5\n",
            "25/26 [===========================>..] - ETA: 6s - loss: 2.1273 - accuracy: 0.5775 \n",
            "Epoch 00005: loss improved from 2.12727 to 2.12469, saving model to /gdrive/My Drive/best_model.h5\n",
            "26/26 [==============================] - ETA: 0s - loss: 2.1247 - accuracy: 0.5769WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 177s 7s/step - loss: 2.1247 - accuracy: 0.5769 - val_loss: 2.4067 - val_accuracy: 0.6250\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: loss improved from 2.12469 to 1.86826, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 1.8683 - accuracy: 0.6250\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 2/26 [=>............................] - ETA: 1:19 - loss: 2.0183 - accuracy: 0.5625\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 3/26 [==>...........................] - ETA: 1:36 - loss: 2.0219 - accuracy: 0.5833\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 4/26 [===>..........................] - ETA: 1:39 - loss: 2.0248 - accuracy: 0.5859\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 5/26 [====>.........................] - ETA: 1:47 - loss: 1.9848 - accuracy: 0.6062\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 6/26 [=====>........................] - ETA: 1:44 - loss: 1.9605 - accuracy: 0.6250\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 7/26 [=======>......................] - ETA: 1:43 - loss: 1.9776 - accuracy: 0.6116\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 8/26 [========>.....................] - ETA: 1:39 - loss: 2.0379 - accuracy: 0.5938\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            " 9/26 [=========>....................] - ETA: 1:36 - loss: 2.0360 - accuracy: 0.5972\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "10/26 [==========>...................] - ETA: 1:32 - loss: 2.0056 - accuracy: 0.5969\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "11/26 [===========>..................] - ETA: 1:26 - loss: 1.9831 - accuracy: 0.5938\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "12/26 [============>.................] - ETA: 1:20 - loss: 1.9709 - accuracy: 0.5859\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "13/26 [==============>...............] - ETA: 1:16 - loss: 1.9639 - accuracy: 0.5865\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "14/26 [===============>..............] - ETA: 1:12 - loss: 1.9638 - accuracy: 0.5871\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "15/26 [================>.............] - ETA: 1:06 - loss: 2.0167 - accuracy: 0.5729\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "16/26 [=================>............] - ETA: 1:00 - loss: 2.0358 - accuracy: 0.5664\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "17/26 [==================>...........] - ETA: 54s - loss: 2.0323 - accuracy: 0.5717 \n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "18/26 [===================>..........] - ETA: 48s - loss: 2.0249 - accuracy: 0.5729\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "19/26 [====================>.........] - ETA: 42s - loss: 2.0355 - accuracy: 0.5658\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "20/26 [======================>.......] - ETA: 36s - loss: 2.0265 - accuracy: 0.5656\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "21/26 [=======================>......] - ETA: 30s - loss: 2.0237 - accuracy: 0.5670\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "22/26 [========================>.....] - ETA: 24s - loss: 2.0300 - accuracy: 0.5668\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "23/26 [=========================>....] - ETA: 18s - loss: 2.0121 - accuracy: 0.5734\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "24/26 [==========================>...] - ETA: 12s - loss: 2.0101 - accuracy: 0.5794\n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "25/26 [===========================>..] - ETA: 6s - loss: 1.9988 - accuracy: 0.5850 \n",
            "Epoch 00006: loss did not improve from 1.86826\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.9959 - accuracy: 0.5829WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 171s 7s/step - loss: 1.9959 - accuracy: 0.5829 - val_loss: 1.9428 - val_accuracy: 0.5938\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: loss improved from 1.86826 to 1.85051, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 1.8505 - accuracy: 0.5938\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 2/26 [=>............................] - ETA: 1:10 - loss: 2.0073 - accuracy: 0.5469\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 3/26 [==>...........................] - ETA: 1:26 - loss: 1.9360 - accuracy: 0.5938\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 4/26 [===>..........................] - ETA: 1:38 - loss: 1.9632 - accuracy: 0.5938\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 5/26 [====>.........................] - ETA: 1:41 - loss: 1.9408 - accuracy: 0.6000\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 6/26 [=====>........................] - ETA: 1:44 - loss: 1.9258 - accuracy: 0.6094\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 7/26 [=======>......................] - ETA: 1:40 - loss: 1.9086 - accuracy: 0.5982\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 8/26 [========>.....................] - ETA: 1:34 - loss: 1.9353 - accuracy: 0.6172\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            " 9/26 [=========>....................] - ETA: 1:31 - loss: 1.9347 - accuracy: 0.6042\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "10/26 [==========>...................] - ETA: 1:26 - loss: 1.9691 - accuracy: 0.6062\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "11/26 [===========>..................] - ETA: 1:21 - loss: 1.9863 - accuracy: 0.5994\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "12/26 [============>.................] - ETA: 1:16 - loss: 1.9517 - accuracy: 0.6042\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "13/26 [==============>...............] - ETA: 1:10 - loss: 1.9579 - accuracy: 0.5962\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "14/26 [===============>..............] - ETA: 1:05 - loss: 1.9445 - accuracy: 0.5982\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "15/26 [================>.............] - ETA: 1:01 - loss: 1.9441 - accuracy: 0.6000\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "16/26 [=================>............] - ETA: 55s - loss: 1.9525 - accuracy: 0.6055 \n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "17/26 [==================>...........] - ETA: 50s - loss: 1.9683 - accuracy: 0.5993\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "18/26 [===================>..........] - ETA: 45s - loss: 1.9638 - accuracy: 0.5990\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "19/26 [====================>.........] - ETA: 39s - loss: 1.9559 - accuracy: 0.6086\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "20/26 [======================>.......] - ETA: 34s - loss: 1.9625 - accuracy: 0.6047\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "21/26 [=======================>......] - ETA: 28s - loss: 1.9540 - accuracy: 0.5997\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "22/26 [========================>.....] - ETA: 22s - loss: 1.9497 - accuracy: 0.6023\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "23/26 [=========================>....] - ETA: 17s - loss: 1.9638 - accuracy: 0.5965\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "24/26 [==========================>...] - ETA: 11s - loss: 1.9576 - accuracy: 0.5990\n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "25/26 [===========================>..] - ETA: 5s - loss: 1.9628 - accuracy: 0.5950 \n",
            "Epoch 00007: loss did not improve from 1.85051\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.9521 - accuracy: 0.5986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 158s 6s/step - loss: 1.9521 - accuracy: 0.5986 - val_loss: 1.9018 - val_accuracy: 0.6562\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: loss improved from 1.85051 to 1.78325, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 1.7832 - accuracy: 0.6250\n",
            "Epoch 00008: loss did not improve from 1.78325\n",
            " 2/26 [=>............................] - ETA: 58s - loss: 1.8554 - accuracy: 0.5938\n",
            "Epoch 00008: loss did not improve from 1.78325\n",
            " 3/26 [==>...........................] - ETA: 1:28 - loss: 1.8178 - accuracy: 0.6354\n",
            "Epoch 00008: loss improved from 1.78325 to 1.77187, saving model to /gdrive/My Drive/best_model.h5\n",
            " 4/26 [===>..........................] - ETA: 1:35 - loss: 1.7719 - accuracy: 0.6484\n",
            "Epoch 00008: loss improved from 1.77187 to 1.74640, saving model to /gdrive/My Drive/best_model.h5\n",
            " 5/26 [====>.........................] - ETA: 1:28 - loss: 1.7464 - accuracy: 0.6438\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            " 6/26 [=====>........................] - ETA: 1:27 - loss: 1.7891 - accuracy: 0.6510\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            " 7/26 [=======>......................] - ETA: 1:26 - loss: 1.8075 - accuracy: 0.6562\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            " 8/26 [========>.....................] - ETA: 1:26 - loss: 1.8229 - accuracy: 0.6445\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            " 9/26 [=========>....................] - ETA: 1:25 - loss: 1.7775 - accuracy: 0.6597\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "10/26 [==========>...................] - ETA: 1:20 - loss: 1.8332 - accuracy: 0.6531\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "11/26 [===========>..................] - ETA: 1:16 - loss: 1.8151 - accuracy: 0.6534\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "12/26 [============>.................] - ETA: 1:11 - loss: 1.8342 - accuracy: 0.6406\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "13/26 [==============>...............] - ETA: 1:06 - loss: 1.8368 - accuracy: 0.6442\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "14/26 [===============>..............] - ETA: 1:02 - loss: 1.9027 - accuracy: 0.6406\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "15/26 [================>.............] - ETA: 58s - loss: 1.8977 - accuracy: 0.6417 \n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "16/26 [=================>............] - ETA: 53s - loss: 1.8995 - accuracy: 0.6445\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "17/26 [==================>...........] - ETA: 48s - loss: 1.9056 - accuracy: 0.6452\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "18/26 [===================>..........] - ETA: 43s - loss: 1.9107 - accuracy: 0.6424\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "19/26 [====================>.........] - ETA: 37s - loss: 1.9320 - accuracy: 0.6365\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "20/26 [======================>.......] - ETA: 32s - loss: 1.9316 - accuracy: 0.6359\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "21/26 [=======================>......] - ETA: 27s - loss: 1.9243 - accuracy: 0.6354\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "22/26 [========================>.....] - ETA: 21s - loss: 1.9210 - accuracy: 0.6321\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "23/26 [=========================>....] - ETA: 16s - loss: 1.9215 - accuracy: 0.6345\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "24/26 [==========================>...] - ETA: 10s - loss: 1.9057 - accuracy: 0.6315\n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "25/26 [===========================>..] - ETA: 5s - loss: 1.9031 - accuracy: 0.6288 \n",
            "Epoch 00008: loss did not improve from 1.74640\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.9086 - accuracy: 0.6214WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 150s 6s/step - loss: 1.9086 - accuracy: 0.6214 - val_loss: 2.2530 - val_accuracy: 0.4688\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: loss did not improve from 1.74640\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 1.8341 - accuracy: 0.6875\n",
            "Epoch 00009: loss did not improve from 1.74640\n",
            " 2/26 [=>............................] - ETA: 54s - loss: 1.8982 - accuracy: 0.6250\n",
            "Epoch 00009: loss did not improve from 1.74640\n",
            " 3/26 [==>...........................] - ETA: 1:16 - loss: 1.7908 - accuracy: 0.6667\n",
            "Epoch 00009: loss did not improve from 1.74640\n",
            " 4/26 [===>..........................] - ETA: 1:28 - loss: 1.7702 - accuracy: 0.6406\n",
            "Epoch 00009: loss improved from 1.74640 to 1.74537, saving model to /gdrive/My Drive/best_model.h5\n",
            " 5/26 [====>.........................] - ETA: 1:32 - loss: 1.7454 - accuracy: 0.6313\n",
            "Epoch 00009: loss improved from 1.74537 to 1.71594, saving model to /gdrive/My Drive/best_model.h5\n",
            " 6/26 [=====>........................] - ETA: 1:29 - loss: 1.7159 - accuracy: 0.6458\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            " 7/26 [=======>......................] - ETA: 1:27 - loss: 1.7381 - accuracy: 0.6429\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            " 8/26 [========>.....................] - ETA: 1:24 - loss: 1.7754 - accuracy: 0.6328\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            " 9/26 [=========>....................] - ETA: 1:21 - loss: 1.7721 - accuracy: 0.6215\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "10/26 [==========>...................] - ETA: 1:17 - loss: 1.7634 - accuracy: 0.6219\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "11/26 [===========>..................] - ETA: 1:12 - loss: 1.7573 - accuracy: 0.6307\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "12/26 [============>.................] - ETA: 1:08 - loss: 1.7548 - accuracy: 0.6302\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "13/26 [==============>...............] - ETA: 1:03 - loss: 1.7290 - accuracy: 0.6346\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "14/26 [===============>..............] - ETA: 59s - loss: 1.7505 - accuracy: 0.6317 \n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "15/26 [================>.............] - ETA: 54s - loss: 1.7446 - accuracy: 0.6313\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "16/26 [=================>............] - ETA: 49s - loss: 1.7508 - accuracy: 0.6309\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "17/26 [==================>...........] - ETA: 44s - loss: 1.7521 - accuracy: 0.6287\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "18/26 [===================>..........] - ETA: 40s - loss: 1.7640 - accuracy: 0.6181\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "19/26 [====================>.........] - ETA: 35s - loss: 1.7639 - accuracy: 0.6234\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "20/26 [======================>.......] - ETA: 30s - loss: 1.7624 - accuracy: 0.6156\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "21/26 [=======================>......] - ETA: 25s - loss: 1.7533 - accuracy: 0.6190\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "22/26 [========================>.....] - ETA: 20s - loss: 1.7504 - accuracy: 0.6136\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "23/26 [=========================>....] - ETA: 15s - loss: 1.7453 - accuracy: 0.6182\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "24/26 [==========================>...] - ETA: 10s - loss: 1.7361 - accuracy: 0.6198\n",
            "Epoch 00009: loss did not improve from 1.71594\n",
            "25/26 [===========================>..] - ETA: 5s - loss: 1.7280 - accuracy: 0.6263 \n",
            "Epoch 00009: loss improved from 1.71594 to 1.71527, saving model to /gdrive/My Drive/best_model.h5\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.7153 - accuracy: 0.6298WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 140s 5s/step - loss: 1.7153 - accuracy: 0.6298 - val_loss: 1.6390 - val_accuracy: 0.7188\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: loss improved from 1.71527 to 1.49296, saving model to /gdrive/My Drive/best_model.h5\n",
            " 1/26 [>.............................] - ETA: 0s - loss: 1.4930 - accuracy: 0.7188\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 2/26 [=>............................] - ETA: 58s - loss: 1.6445 - accuracy: 0.6719\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 3/26 [==>...........................] - ETA: 1:24 - loss: 1.7592 - accuracy: 0.6042\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 4/26 [===>..........................] - ETA: 1:27 - loss: 1.7512 - accuracy: 0.6328\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 5/26 [====>.........................] - ETA: 1:29 - loss: 1.7063 - accuracy: 0.6500\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 6/26 [=====>........................] - ETA: 1:27 - loss: 1.6606 - accuracy: 0.6562\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 8/26 [========>.....................] - ETA: 1:24 - loss: 1.6898 - accuracy: 0.6445\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            " 9/26 [=========>....................] - ETA: 1:19 - loss: 1.6690 - accuracy: 0.6528\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "10/26 [==========>...................] - ETA: 1:16 - loss: 1.6543 - accuracy: 0.6594\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "11/26 [===========>..................] - ETA: 1:13 - loss: 1.6359 - accuracy: 0.6562\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "12/26 [============>.................] - ETA: 1:09 - loss: 1.6301 - accuracy: 0.6693\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "13/26 [==============>...............] - ETA: 1:03 - loss: 1.6409 - accuracy: 0.6659\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "14/26 [===============>..............] - ETA: 58s - loss: 1.6498 - accuracy: 0.6607 \n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "16/26 [=================>............] - ETA: 46s - loss: 1.6362 - accuracy: 0.6619\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "17/26 [==================>...........] - ETA: 42s - loss: 1.6294 - accuracy: 0.6673\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "18/26 [===================>..........] - ETA: 38s - loss: 1.6187 - accuracy: 0.6667\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "19/26 [====================>.........] - ETA: 34s - loss: 1.5970 - accuracy: 0.6781\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "20/26 [======================>.......] - ETA: 29s - loss: 1.5883 - accuracy: 0.6786\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "22/26 [========================>.....] - ETA: 19s - loss: 1.6051 - accuracy: 0.6795\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "23/26 [=========================>....] - ETA: 14s - loss: 1.5968 - accuracy: 0.6756\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "24/26 [==========================>...] - ETA: 9s - loss: 1.5953 - accuracy: 0.6721 \n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "25/26 [===========================>..] - ETA: 4s - loss: 1.5841 - accuracy: 0.6714\n",
            "Epoch 00010: loss did not improve from 1.49296\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.5860 - accuracy: 0.6720WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "26/26 [==============================] - 135s 5s/step - loss: 1.5860 - accuracy: 0.6720 - val_loss: 2.2338 - val_accuracy: 0.4688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVOirdl-iC9T"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(10)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb_dc04wqKXN",
        "outputId": "0d92e289-0241-4bcb-d2c6-b54e918b0f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4btSlUsfWbUd"
      },
      "source": [
        "save_dir = \"/gdrive/My Drive\"\n",
        "json_file = open(save_dir+\"/Abbos.json\", \"w\")\n",
        "model_json = model.to_json()\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "model.save_weights(save_dir+\"/Abbos_weights.h5\")"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}